% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gradientproj.R
\name{gradientproj}
\alias{gradientproj}
\title{Constrained optimization with Gradient Projection}
\usage{
gradientproj(obj.list, x.list, constraint, maxNI = 50, eps = 1e-04,
  alpha0 = 1, c = 1e-04, rho = 0.5, ...)
}
\arguments{
\item{obj.list}{Either an objective function or a list with the following
names \cr
  f: objective function
  df: gradient of f (it not provided, defaults to the numerical version)}

\item{x.list}{Either a vector with an initial solution or a list with the
following names \cr
  x: a vector with its value in the search space \cr
  fx: a scalar with its objective value \cr
  dfx: a vector with its gradient value \cr}

\item{constraint}{A list, with the following names \cr
xmin: lower restriction \cr
xmax: upper restraint \cr}

\item{maxNI}{maximum number of iterations}

\item{eps}{tolerance for stop codition}

\item{alpha0}{Initial step size in the backtracking}

\item{c}{A small constant, control parameter.}

\item{rho}{A constant to reduce alpha in backtracking}
}
\value{
Returns a list with the (approximate) optimum.
}
\description{
\code{gradientproj} solves a multivariate function with constraints using the
Gradient Projection.
}
\examples{

}
\references{
\enumerate{
\item Nocedal, C.T.; \emph{Iterative Methods for optimization}.
}
}
